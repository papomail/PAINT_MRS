{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_from_csv(csv_file, row=3, header=1):\n",
    "        lwp_ind = str(csv_file).lower().find('lwp')\n",
    "        lwp = str(csv_file)[lwp_ind:lwp_ind+14]\n",
    "        df = pd.read_csv(csv_file, header=[header], on_bad_lines='skip')\n",
    "        try:\n",
    "            return [lwp,*df.iloc[row].name]\n",
    "        except:\n",
    "            return [lwp,*df.iloc[row]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def met_ratio(df, up, down, error_method='Cramer', error_label=' Error (SD)', output='both'):\n",
    "    if not isinstance(up,list):\n",
    "        up = [up]\n",
    "    if not isinstance(down,list):\n",
    "        down = [down]    \n",
    "   \n",
    "    up_err_name = [f'{item}{error_label}' for item in up]\n",
    "    down_err_name = [f'{item}{error_label}' for item in down]\n",
    "    for item in np.concatenate([up_err_name, down_err_name]).flat:\n",
    "        if item not in df.columns:\n",
    "            raise KeyError(f'Cannot find \"{item}\" in the DataFrame. Please check the given name is correct.')\n",
    "    \n",
    "    up_amp = df[up].astype(float).sum(axis=1)\n",
    "    down_amp = df[down].astype(float).sum(axis=1)\n",
    "    if error_method.lower() == 'cramer':\n",
    "        up_err = (df[up_err_name].astype(float)**2).sum(axis=1) ** 0.5\n",
    "        down_err = (df[down_err_name].astype(float)**2).sum(axis=1) ** 0.5\n",
    "    elif error_method.lower()=='narrow':\n",
    "        up_err = df[up_err_name].astype(float).max(axis=1) \n",
    "        down_err = df[down_err_name].astype(float).max(axis=1) \n",
    "    else:\n",
    "        raise KeyError('Please choose \"Cramer\" or \"Narrow\" for the error_method')\n",
    "    \n",
    "    ratio = up_amp / down_amp\n",
    "    ratio_err = ratio * ((up_err/up_amp)**2 + (down_err/down_amp)**2)**0.5 \n",
    "    \n",
    "    if len(up)>1:\n",
    "        up_label =f'({\"+\".join(up)})'\n",
    "    else:\n",
    "        up_label = f'{\"+\".join(up)}'\n",
    "    if len(down)>1:\n",
    "        down_label = f'({\"+\".join(down)})'\n",
    "    else:\n",
    "        down_label = f'{\"+\".join(down)}'    \n",
    "    col_name = f'{up_label}/{down_label}'   \n",
    "    col_error_name = f'{col_name} Error (SD) {error_method}'\n",
    "    \n",
    "    if output=='both':\n",
    "        return pd.DataFrame({col_name: ratio, col_error_name: ratio_err})\n",
    "    elif output=='ratio':\n",
    "        return pd.DataFrame({col_name: ratio})      \n",
    "    elif output=='error':\n",
    "        return pd.DataFrame({col_error_name: ratio_err})   \n",
    "    else:\n",
    "        raise KeyError('Please choose \"ratio\", \"error\" or \"both\" (default) as output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 13058.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# data_folder = Path('/Users/papo/Sync/MRdata/IoN_Piglet/MRS_RAY')\n",
    "# data_folder = Path('/Users/papo/Sync/MRdata/IoN_Piglet/Ellie')\n",
    "data_folder = Path('/Users/patxi/Sync/Projects/PAINT_MRS/INSPIRE_MRS_DATA')\n",
    "\n",
    "basis_folder = Path('/Users/patxi/Sync/Projects/PAINT_MRS/3_0T_basis_threonine')\n",
    "\n",
    "sdat_files = [f for f in sorted(data_folder.rglob('*')) if (\"act.sdat\" in f.name.lower() and \"press_35\".lower() in f.name.lower())]\n",
    "for file in tqdm(sdat_files):\n",
    "    ref = Path(f'{str(file)[0:-8]}ref.SDAT')\n",
    "    csv = Path(f'{str(file)[0:-5]}_PRESS_35_WM.csv')\n",
    "    pdf = Path(f'{str(file)[0:-4]}pdf')\n",
    "    # print(csv)\n",
    "    if not csv.is_file():\n",
    "        # command = f'tarquin --rows 3 --cols 2 --input {file} --output_pdf {pdf} --output_csv {csv} --input_w {ref} --basis_csv {basis_folder}'\n",
    "        # command = f'tarquin --rows 3 --cols 2 --input {file} --output_csv {csv} --input_w {ref} --basis_csv {basis_folder}'\n",
    "        command = f'tarquin --input {file} --output_csv {csv} --input_w {ref} --basis_csv {basis_folder}'\n",
    "\n",
    "        print(f'{command}\\n') \n",
    "        os.system(command)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "105 columns passed, passed data had 107 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/pat3/lib/python3.9/site-packages/pandas/core/internals/construction.py:982\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    984\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pat3/lib/python3.9/site-packages/pandas/core/internals/construction.py:1030\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m-> 1030\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m   1031\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1032\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[1;32m   1034\u001b[0m \u001b[39melif\u001b[39;00m is_mi_list:\n\u001b[1;32m   1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 105 columns passed, passed data had 107 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/patxi/Sync/Projects/PAINT_MRS/PRESS_INSPIRE.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patxi/Sync/Projects/PAINT_MRS/PRESS_INSPIRE.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m my_errors \u001b[39m=\u001b[39m [item\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Error (SD)\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m my_columns]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patxi/Sync/Projects/PAINT_MRS/PRESS_INSPIRE.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m my_diagnostics \u001b[39m=\u001b[39m pull_from_csv(file,row\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)    \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patxi/Sync/Projects/PAINT_MRS/PRESS_INSPIRE.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data_list, columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mLWP\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49mmy_columns, \u001b[39m'\u001b[39;49m\u001b[39mError for LWP\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49mmy_errors,\u001b[39m*\u001b[39;49mmy_diagnostics ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patxi/Sync/Projects/PAINT_MRS/PRESS_INSPIRE.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df\u001b[39m.\u001b[39mto_excel(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m.xlsx\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patxi/Sync/Projects/PAINT_MRS/PRESS_INSPIRE.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#now calculate ratios\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pat3/lib/python3.9/site-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m         \u001b[39m# error: Argument 1 to \"ensure_index\" has incompatible type\u001b[39;00m\n\u001b[1;32m    718\u001b[0m         \u001b[39m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m    719\u001b[0m         \u001b[39m# ndarray], Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    722\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    724\u001b[0m         data,\n\u001b[1;32m    725\u001b[0m         columns,\n\u001b[1;32m    726\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    727\u001b[0m         dtype,\n\u001b[1;32m    728\u001b[0m     )\n\u001b[1;32m    729\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    730\u001b[0m         arrays,\n\u001b[1;32m    731\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    735\u001b[0m     )\n\u001b[1;32m    736\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pat3/lib/python3.9/site-packages/pandas/core/internals/construction.py:519\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 519\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    520\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    522\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/pat3/lib/python3.9/site-packages/pandas/core/internals/construction.py:883\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    880\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m    881\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 883\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    884\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/.virtualenvs/pat3/lib/python3.9/site-packages/pandas/core/internals/construction.py:985\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    982\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    984\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 985\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m    988\u001b[0m     contents \u001b[39m=\u001b[39m _convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 105 columns passed, passed data had 107 columns"
     ]
    }
   ],
   "source": [
    "csv_files = [f for f in sorted(data_folder.rglob('*'), key=lambda x:x.parent.parent.stem[4:6]) if (\"press_35\" in f.name.lower() and \".csv\" in f.name.lower())]\n",
    "\n",
    "\n",
    "\n",
    "rows_to_process = {\n",
    "                   'WM': 0,\n",
    "                   }\n",
    "\n",
    "for label,row_num in rows_to_process.items():\n",
    "    data_list = []\n",
    "    for file in csv_files:\n",
    "        data_list.append([*pull_from_csv(file,row=row_num),*pull_from_csv(file,row=row_num+3),*pull_from_csv(file,header=6,row=row_num+1)])\n",
    "    # print(f'{data_list=}')\n",
    "    my_columns = list(pd.read_csv(file, header=[1], on_bad_lines='skip'))\n",
    "    my_errors = [item+' Error (SD)' for item in my_columns]\n",
    "    my_diagnostics = pull_from_csv(file,row=0, header=6)    \n",
    "    df = pd.DataFrame(data_list, columns=['LWP', *my_columns, 'Error for LWP', *my_errors,*my_diagnostics ])\n",
    "    df.to_excel(f'{label}.xlsx', index=False)\n",
    "    \n",
    "    #now calculate ratios\n",
    "    df_L2N = met_ratio(df,['Lac', 'Threonine'], 'TNAA')\n",
    "    df_L2N_narrow_error = met_ratio(df,['Lac', 'Threonine'], 'TNAA', error_method='Narrow', output='error')\n",
    "    df_N2C = met_ratio(df,'TNAA', 'TCho')\n",
    "    df_C2C = met_ratio(df,'TCho', 'Cr')\n",
    "    df_N2Cr = met_ratio(df,'TNAA', 'Cr')\n",
    "\n",
    "\n",
    "    # df_ratio = pd.concat((df_L2N, df_N2C, df_C2C, df_N2C, df), axis=1)\n",
    "    df_ratio = pd.concat((df_L2N,df_L2N_narrow_error, df_N2C, df_C2C, df_N2Cr, df), axis=1)\n",
    "\n",
    "    df_ratio.set_index('LWP').to_excel(f'{label}_RATIOS_PRESS_INSPIRE.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbb = met_ratio(df,'TNAA', 'TCho', error_method='Narrow', output='error')\n",
    "dfbb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Row',\n",
       " 'Col',\n",
       " 'Slice',\n",
       " '-CrCH2',\n",
       " 'Ala',\n",
       " 'Asp',\n",
       " 'Cr',\n",
       " 'GABA',\n",
       " 'GPC',\n",
       " 'Glc',\n",
       " 'Gln',\n",
       " 'Glu',\n",
       " 'Gua',\n",
       " 'Ins',\n",
       " 'Lac',\n",
       " 'Lip09',\n",
       " 'Lip13a',\n",
       " 'Lip13b',\n",
       " 'Lip20',\n",
       " 'MM09',\n",
       " 'MM12',\n",
       " 'MM14',\n",
       " 'MM17',\n",
       " 'MM20',\n",
       " 'NAA',\n",
       " 'NAAG',\n",
       " 'PCh',\n",
       " 'Scyllo',\n",
       " 'Tau',\n",
       " 'TNAA',\n",
       " 'TCho',\n",
       " 'Glx',\n",
       " 'TLM09',\n",
       " 'TLM13',\n",
       " 'TLM20']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Row',\n",
       " 'Col',\n",
       " 'Slice',\n",
       " '-CrCH2',\n",
       " 'Ala',\n",
       " 'Asp',\n",
       " 'Cr',\n",
       " 'GABA',\n",
       " 'GPC',\n",
       " 'Glc',\n",
       " 'Gln',\n",
       " 'Glu',\n",
       " 'Gua',\n",
       " 'Ins',\n",
       " 'Lac',\n",
       " 'Lip09',\n",
       " 'Lip13a',\n",
       " 'Lip13b',\n",
       " 'Lip20',\n",
       " 'MM09',\n",
       " 'MM12',\n",
       " 'MM14',\n",
       " 'MM17',\n",
       " 'MM20',\n",
       " 'NAA',\n",
       " 'NAAG',\n",
       " 'PCh',\n",
       " 'Scyllo',\n",
       " 'Tau',\n",
       " 'TNAA',\n",
       " 'TCho',\n",
       " 'Glx',\n",
       " 'TLM09',\n",
       " 'TLM13',\n",
       " 'TLM20']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('pat3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "655a077b08823ae3900d2693341c1892e24458077ed6fb1ad8d35a6d8f768e5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
